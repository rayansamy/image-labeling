{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd087ca9f09b7ab97f4b0c2b431eda3d3c04a7d0df0284a0aa2f4790ab8b5423040",
   "display_name": "Python 3.8.8 64-bit ('clipenv': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "87ca9f09b7ab97f4b0c2b431eda3d3c04a7d0df0284a0aa2f4790ab8b5423040"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(photo_batch):\n",
    "    images = []\n",
    "    batch_photo_ids = []\n",
    "    for pf in photo_batch:\n",
    "        images.append(preprocess(Image.open(pf)))\n",
    "        batch_photo_ids.append(pf.name.split('.jpg')[0])\n",
    "    images_tensor = torch.stack(images).to(device)\n",
    "    with torch.no_grad():\n",
    "        images_features = model.encode_image(images_tensor)\n",
    "        images_features /= images_features.norm(dim=-1, keepdim=True)\n",
    "    return images_features.cpu(), batch_photo_ids"
   ]
  }
 ]
}